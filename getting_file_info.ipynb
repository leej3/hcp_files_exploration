{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "dir = {'900':'/data/HCP/HCP_900/s3/hcp/','1200': '/data/HCP/HCP_1200'}\n",
    "cols = ['perms','links','user','group','size','year','time','dir']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_path(dataset):\n",
    "    return Path('files_characterization_' + dataset + '.pklz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir = {'test': '/data/HCP/HCP_1200/download_swarm/**/*'}\n",
    "for dataset,d_path in dir.items():\n",
    "    output_file = get_output_path(dataset)\n",
    "    #     -lu gives access time\n",
    "    #     -d1 gives just the file/dir instead of the contents\n",
    "    #     the glob pattern provides all the files/dirs\n",
    "    #     the awk command turns it into tab separated output\n",
    "    !ls -lu -d1  --time-style long-iso {d_path} | awk -v OFS=\"\\t\" '$1=$1' > {output_file.with_suffix('.tsv')}\n",
    "    df = pd.read_csv(output_file.with_suffix('.tsv'),sep = '\\t',names=cols)\n",
    "    df.to_pickle(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "df_900 = pd.read_pickle(get_output_path('900'))\n",
    "df_1200 = pd.read_pickle(get_output_path('1200'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file.with_suffix('.tsv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
